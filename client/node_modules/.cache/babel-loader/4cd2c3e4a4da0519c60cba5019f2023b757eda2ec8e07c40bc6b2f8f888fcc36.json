{"ast":null,"code":"\"use strict\";\n\nvar _objectSpread = require(\"/Users/glebch/workprojects/baumna/client/node_modules/@babel/runtime/helpers/objectSpread2.js\").default;\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = require(\"stream\");\nconst bson_1 = require(\"../bson\");\nconst abstract_cursor_1 = require(\"../cursor/abstract_cursor\");\nconst error_1 = require(\"../error\");\nconst timeout_1 = require(\"../timeout\");\nconst utils_1 = require(\"../utils\");\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket, filename, options) {\n    super();\n    /**\n     * The document containing information about the inserted file.\n     * This property is defined _after_ the finish event has been emitted.\n     * It will remain `null` if an error occurs.\n     *\n     * @example\n     * ```ts\n     * fs.createReadStream('file.txt')\n     *   .pipe(bucket.openUploadStream('file.txt'))\n     *   .on('finish', function () {\n     *     console.log(this.gridFSFile)\n     *   })\n     * ```\n     */\n    this.gridFSFile = null;\n    options = options !== null && options !== void 0 ? options : {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n    this.id = options.id ? options.id : new bson_1.ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n    if (options.timeoutMS != null) this.timeoutContext = new timeout_1.CSOTTimeoutContext({\n      timeoutMS: options.timeoutMS,\n      serverSelectionTimeoutMS: (0, utils_1.resolveTimeoutOptions)(this.bucket.s.db.client, {}).serverSelectionTimeoutMS\n    });\n  }\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  _construct(callback) {\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(this).then(() => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n        callback();\n      }, error => {\n        if (error instanceof error_1.MongoOperationTimeoutError) {\n          return handleError(this, error, callback);\n        }\n        (0, utils_1.squashError)(error);\n        callback();\n      });\n    } else {\n      return process.nextTick(callback);\n    }\n  }\n  /**\n   * @internal\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   */\n  _write(chunk, encoding, callback) {\n    doWrite(this, chunk, encoding, callback);\n  }\n  /** @internal */\n  _final(callback) {\n    if (this.state.streamEnd) {\n      return process.nextTick(callback);\n    }\n    this.state.streamEnd = true;\n    writeRemnant(this, callback);\n  }\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n  async abort() {\n    var _this$timeoutContext, _this$timeoutContext2;\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n    }\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n    }\n    this.state.aborted = true;\n    const remainingTimeMS = (_this$timeoutContext = this.timeoutContext) === null || _this$timeoutContext === void 0 ? void 0 : _this$timeoutContext.getRemainingTimeMSOrThrow(\"Upload timed out after \".concat((_this$timeoutContext2 = this.timeoutContext) === null || _this$timeoutContext2 === void 0 ? void 0 : _this$timeoutContext2.timeoutMS, \"ms\"));\n    await this.chunks.deleteMany({\n      files_id: this.id\n    }, {\n      timeoutMS: remainingTimeMS\n    });\n  }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\nasync function checkChunksIndex(stream) {\n  var _stream$timeoutContex, _stream$timeoutContex2;\n  const index = {\n    files_id: 1,\n    n: 1\n  };\n  let remainingTimeMS;\n  remainingTimeMS = (_stream$timeoutContex = stream.timeoutContext) === null || _stream$timeoutContex === void 0 ? void 0 : _stream$timeoutContex.getRemainingTimeMSOrThrow(\"Upload timed out after \".concat((_stream$timeoutContex2 = stream.timeoutContext) === null || _stream$timeoutContex2 === void 0 ? void 0 : _stream$timeoutContex2.timeoutMS, \"ms\"));\n  let indexes;\n  try {\n    indexes = await stream.chunks.listIndexes({\n      timeoutMode: remainingTimeMS != null ? abstract_cursor_1.CursorTimeoutMode.LIFETIME : undefined,\n      timeoutMS: remainingTimeMS\n    }).toArray();\n  } catch (error) {\n    if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n  if (!hasChunksIndex) {\n    var _stream$timeoutContex3, _stream$timeoutContex4;\n    remainingTimeMS = (_stream$timeoutContex3 = stream.timeoutContext) === null || _stream$timeoutContex3 === void 0 ? void 0 : _stream$timeoutContex3.getRemainingTimeMSOrThrow(\"Upload timed out after \".concat((_stream$timeoutContex4 = stream.timeoutContext) === null || _stream$timeoutContex4 === void 0 ? void 0 : _stream$timeoutContex4.timeoutMS, \"ms\"));\n    await stream.chunks.createIndex(index, _objectSpread(_objectSpread({}, stream.writeConcern), {}, {\n      background: true,\n      unique: true,\n      timeoutMS: remainingTimeMS\n    }));\n  }\n}\nfunction checkDone(stream, callback) {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    var _stream$timeoutContex5;\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n    if (isAborted(stream, callback)) {\n      return;\n    }\n    const remainingTimeMS = (_stream$timeoutContex5 = stream.timeoutContext) === null || _stream$timeoutContex5 === void 0 ? void 0 : _stream$timeoutContex5.remainingTimeMS;\n    if (remainingTimeMS != null && remainingTimeMS <= 0) {\n      var _stream$timeoutContex6;\n      return handleError(stream, new error_1.MongoOperationTimeoutError(\"Upload timed out after \".concat((_stream$timeoutContex6 = stream.timeoutContext) === null || _stream$timeoutContex6 === void 0 ? void 0 : _stream$timeoutContex6.timeoutMS, \"ms\")), callback);\n    }\n    stream.files.insertOne(gridFSFile, {\n      writeConcern: stream.writeConcern,\n      timeoutMS: remainingTimeMS\n    }).then(() => {\n      stream.gridFSFile = gridFSFile;\n      callback();\n    }, error => {\n      return handleError(stream, error, callback);\n    });\n    return;\n  }\n  process.nextTick(callback);\n}\nasync function checkIndexes(stream) {\n  var _stream$timeoutContex7, _stream$timeoutContex8, _stream$timeoutContex9, _stream$timeoutContex10;\n  let remainingTimeMS = (_stream$timeoutContex7 = stream.timeoutContext) === null || _stream$timeoutContex7 === void 0 ? void 0 : _stream$timeoutContex7.getRemainingTimeMSOrThrow(\"Upload timed out after \".concat((_stream$timeoutContex8 = stream.timeoutContext) === null || _stream$timeoutContex8 === void 0 ? void 0 : _stream$timeoutContex8.timeoutMS, \"ms\"));\n  const doc = await stream.files.findOne({}, {\n    projection: {\n      _id: 1\n    },\n    timeoutMS: remainingTimeMS\n  });\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n  const index = {\n    filename: 1,\n    uploadDate: 1\n  };\n  let indexes;\n  remainingTimeMS = (_stream$timeoutContex9 = stream.timeoutContext) === null || _stream$timeoutContex9 === void 0 ? void 0 : _stream$timeoutContex9.getRemainingTimeMSOrThrow(\"Upload timed out after \".concat((_stream$timeoutContex10 = stream.timeoutContext) === null || _stream$timeoutContex10 === void 0 ? void 0 : _stream$timeoutContex10.timeoutMS, \"ms\"));\n  const listIndexesOptions = {\n    timeoutMode: remainingTimeMS != null ? abstract_cursor_1.CursorTimeoutMode.LIFETIME : undefined,\n    timeoutMS: remainingTimeMS\n  };\n  try {\n    indexes = await stream.files.listIndexes(listIndexesOptions).toArray();\n  } catch (error) {\n    if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n  if (!hasFileIndex) {\n    var _stream$timeoutContex11, _stream$timeoutContex12;\n    remainingTimeMS = (_stream$timeoutContex11 = stream.timeoutContext) === null || _stream$timeoutContex11 === void 0 ? void 0 : _stream$timeoutContex11.getRemainingTimeMSOrThrow(\"Upload timed out after \".concat((_stream$timeoutContex12 = stream.timeoutContext) === null || _stream$timeoutContex12 === void 0 ? void 0 : _stream$timeoutContex12.timeoutMS, \"ms\"));\n    await stream.files.createIndex(index, {\n      background: false,\n      timeoutMS: remainingTimeMS\n    });\n  }\n  await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  const ret = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n  return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length;\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc;\n    if (spaceRemaining === 0) {\n      var _stream$timeoutContex13;\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      const remainingTimeMS = (_stream$timeoutContex13 = stream.timeoutContext) === null || _stream$timeoutContex13 === void 0 ? void 0 : _stream$timeoutContex13.remainingTimeMS;\n      if (remainingTimeMS != null && remainingTimeMS <= 0) {\n        var _stream$timeoutContex14;\n        return handleError(stream, new error_1.MongoOperationTimeoutError(\"Upload timed out after \".concat((_stream$timeoutContex14 = stream.timeoutContext) === null || _stream$timeoutContex14 === void 0 ? void 0 : _stream$timeoutContex14.timeoutMS, \"ms\")), callback);\n      }\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n      if (isAborted(stream, callback)) {\n        return;\n      }\n      stream.chunks.insertOne(doc, {\n        writeConcern: stream.writeConcern,\n        timeoutMS: remainingTimeMS\n      }).then(() => {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n        if (!outstandingRequests) {\n          checkDone(stream, callback);\n        }\n      }, error => {\n        return handleError(stream, error, callback);\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\nfunction writeRemnant(stream, callback) {\n  var _stream$timeoutContex15;\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  const remainingTimeMS = (_stream$timeoutContex15 = stream.timeoutContext) === null || _stream$timeoutContex15 === void 0 ? void 0 : _stream$timeoutContex15.remainingTimeMS;\n  if (remainingTimeMS != null && remainingTimeMS <= 0) {\n    var _stream$timeoutContex16;\n    return handleError(stream, new error_1.MongoOperationTimeoutError(\"Upload timed out after \".concat((_stream$timeoutContex16 = stream.timeoutContext) === null || _stream$timeoutContex16 === void 0 ? void 0 : _stream$timeoutContex16.timeoutMS, \"ms\")), callback);\n  }\n  ++stream.state.outstandingRequests;\n  stream.chunks.insertOne(doc, {\n    writeConcern: stream.writeConcern,\n    timeoutMS: remainingTimeMS\n  }).then(() => {\n    --stream.state.outstandingRequests;\n    checkDone(stream, callback);\n  }, error => {\n    return handleError(stream, error, callback);\n  });\n}\nfunction isAborted(stream, callback) {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}","map":{"version":3,"names":["stream_1","require","bson_1","abstract_cursor_1","error_1","timeout_1","utils_1","write_concern_1","GridFSBucketWriteStream","Writable","constructor","bucket","filename","options","gridFSFile","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","WriteConcern","fromOptions","done","id","ObjectId","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","timeoutMS","timeoutContext","CSOTTimeoutContext","serverSelectionTimeoutMS","resolveTimeoutOptions","db","client","_construct","callback","calledOpenUploadStream","checkIndexes","then","checkedIndexes","emit","error","MongoOperationTimeoutError","handleError","squashError","process","nextTick","_write","chunk","encoding","doWrite","_final","writeRemnant","abort","_this$timeoutContext","_this$timeoutContext2","MongoAPIError","remainingTimeMS","getRemainingTimeMSOrThrow","concat","deleteMany","files_id","exports","stream","createChunkDoc","filesId","data","_id","checkChunksIndex","_stream$timeoutContex","_stream$timeoutContex2","index","indexes","listIndexes","timeoutMode","CursorTimeoutMode","LIFETIME","undefined","toArray","MongoError","code","MONGODB_ERROR_CODES","NamespaceNotFound","hasChunksIndex","find","keys","Object","key","_stream$timeoutContex3","_stream$timeoutContex4","createIndex","_objectSpread","background","unique","checkDone","_stream$timeoutContex5","createFilesDoc","contentType","aliases","metadata","isAborted","_stream$timeoutContex6","insertOne","_stream$timeoutContex7","_stream$timeoutContex8","_stream$timeoutContex9","_stream$timeoutContex10","doc","findOne","projection","uploadDate","listIndexesOptions","hasFileIndex","_stream$timeoutContex11","_stream$timeoutContex12","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","inputBufPos","_stream$timeoutContex13","_stream$timeoutContex14","_stream$timeoutContex15","remnant","_stream$timeoutContex16"],"sources":["/Users/glebch/workprojects/baumna/client/node_modules/mongodb/src/gridfs/upload.ts"],"sourcesContent":["import { Writable } from 'stream';\n\nimport { type Document, ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport { CursorTimeoutMode } from '../cursor/abstract_cursor';\nimport {\n  MongoAPIError,\n  MONGODB_ERROR_CODES,\n  MongoError,\n  MongoOperationTimeoutError\n} from '../error';\nimport { CSOTTimeoutContext } from '../timeout';\nimport { type Callback, resolveTimeoutOptions, squashError } from '../utils';\nimport type { WriteConcernOptions } from '../write_concern';\nimport { WriteConcern } from './../write_concern';\nimport type { GridFSFile } from './download';\nimport type { GridFSBucket } from './index';\n\n/** @public */\nexport interface GridFSChunk {\n  _id: ObjectId;\n  files_id: ObjectId;\n  n: number;\n  data: Buffer | Uint8Array;\n}\n\n/** @public */\nexport interface GridFSBucketWriteStreamOptions extends WriteConcernOptions {\n  /** Overwrite this bucket's chunkSizeBytes for this file */\n  chunkSizeBytes?: number;\n  /** Custom file id for the GridFS file. */\n  id?: ObjectId;\n  /** Object to store in the file document's `metadata` field */\n  metadata?: Document;\n  /**\n   * String to store in the file document's `contentType` field.\n   * @deprecated Will be removed in the next major version. Add a contentType field to the metadata document instead.\n   */\n  contentType?: string;\n  /**\n   * Array of strings to store in the file document's `aliases` field.\n   * @deprecated Will be removed in the next major version. Add an aliases field to the metadata document instead.\n   */\n  aliases?: string[];\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nexport class GridFSBucketWriteStream extends Writable {\n  bucket: GridFSBucket;\n  /** A Collection instance where the file's chunks are stored */\n  chunks: Collection<GridFSChunk>;\n  /** A Collection instance where the file's GridFSFile document is stored */\n  files: Collection<GridFSFile>;\n  /** The name of the file */\n  filename: string;\n  /** Options controlling the metadata inserted along with the file */\n  options: GridFSBucketWriteStreamOptions;\n  /** Indicates the stream is finished uploading */\n  done: boolean;\n  /** The ObjectId used for the `_id` field on the GridFSFile document */\n  id: ObjectId;\n  /** The number of bytes that each chunk will be limited to */\n  chunkSizeBytes: number;\n  /** Space used to store a chunk currently being inserted */\n  bufToStore: Buffer;\n  /** Accumulates the number of bytes inserted as the stream uploads chunks */\n  length: number;\n  /** Accumulates the number of chunks inserted as the stream uploads file contents */\n  n: number;\n  /** Tracks the current offset into the buffered bytes being uploaded */\n  pos: number;\n  /** Contains a number of properties indicating the current state of the stream */\n  state: {\n    /** If set the stream has ended */\n    streamEnd: boolean;\n    /** Indicates the number of chunks that still need to be inserted to exhaust the current buffered data */\n    outstandingRequests: number;\n    /** If set an error occurred during insertion */\n    errored: boolean;\n    /** If set the stream was intentionally aborted */\n    aborted: boolean;\n  };\n  /** The write concern setting to be used with every insert operation */\n  writeConcern?: WriteConcern;\n  /**\n   * The document containing information about the inserted file.\n   * This property is defined _after_ the finish event has been emitted.\n   * It will remain `null` if an error occurs.\n   *\n   * @example\n   * ```ts\n   * fs.createReadStream('file.txt')\n   *   .pipe(bucket.openUploadStream('file.txt'))\n   *   .on('finish', function () {\n   *     console.log(this.gridFSFile)\n   *   })\n   * ```\n   */\n  gridFSFile: GridFSFile | null = null;\n  /** @internal */\n  timeoutContext?: CSOTTimeoutContext;\n\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket: GridFSBucket, filename: string, options?: GridFSBucketWriteStreamOptions) {\n    super();\n\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n\n    this.id = options.id ? options.id : new ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (options.timeoutMS != null)\n      this.timeoutContext = new CSOTTimeoutContext({\n        timeoutMS: options.timeoutMS,\n        serverSelectionTimeoutMS: resolveTimeoutOptions(this.bucket.s.db.client, {})\n          .serverSelectionTimeoutMS\n      });\n  }\n\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  override _construct(callback: (error?: Error | null) => void): void {\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n\n      checkIndexes(this).then(\n        () => {\n          this.bucket.s.checkedIndexes = true;\n          this.bucket.emit('index');\n          callback();\n        },\n        error => {\n          if (error instanceof MongoOperationTimeoutError) {\n            return handleError(this, error, callback);\n          }\n          squashError(error);\n          callback();\n        }\n      );\n    } else {\n      return process.nextTick(callback);\n    }\n  }\n\n  /**\n   * @internal\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   */\n  override _write(\n    chunk: Buffer | string,\n    encoding: BufferEncoding,\n    callback: Callback<void>\n  ): void {\n    doWrite(this, chunk, encoding, callback);\n  }\n\n  /** @internal */\n  override _final(callback: (error?: Error | null) => void): void {\n    if (this.state.streamEnd) {\n      return process.nextTick(callback);\n    }\n    this.state.streamEnd = true;\n    writeRemnant(this, callback);\n  }\n\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n  async abort(): Promise<void> {\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot abort a stream that has already completed');\n    }\n\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot call abort() on a stream twice');\n    }\n\n    this.state.aborted = true;\n    const remainingTimeMS = this.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Upload timed out after ${this.timeoutContext?.timeoutMS}ms`\n    );\n\n    await this.chunks.deleteMany({ files_id: this.id }, { timeoutMS: remainingTimeMS });\n  }\n}\n\nfunction handleError(stream: GridFSBucketWriteStream, error: Error, callback: Callback): void {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\n\nfunction createChunkDoc(filesId: ObjectId, n: number, data: Buffer): GridFSChunk {\n  return {\n    _id: new ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nasync function checkChunksIndex(stream: GridFSBucketWriteStream): Promise<void> {\n  const index = { files_id: 1, n: 1 };\n\n  let remainingTimeMS;\n  remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n    `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n  );\n\n  let indexes;\n  try {\n    indexes = await stream.chunks\n      .listIndexes({\n        timeoutMode: remainingTimeMS != null ? CursorTimeoutMode.LIFETIME : undefined,\n        timeoutMS: remainingTimeMS\n      })\n      .toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasChunksIndex) {\n    remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n    );\n    await stream.chunks.createIndex(index, {\n      ...stream.writeConcern,\n      background: true,\n      unique: true,\n      timeoutMS: remainingTimeMS\n    });\n  }\n}\n\nfunction checkDone(stream: GridFSBucketWriteStream, callback: Callback): void {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const gridFSFile = createFilesDoc(\n      stream.id,\n      stream.length,\n      stream.chunkSizeBytes,\n      stream.filename,\n      stream.options.contentType,\n      stream.options.aliases,\n      stream.options.metadata\n    );\n\n    if (isAborted(stream, callback)) {\n      return;\n    }\n\n    const remainingTimeMS = stream.timeoutContext?.remainingTimeMS;\n    if (remainingTimeMS != null && remainingTimeMS <= 0) {\n      return handleError(\n        stream,\n        new MongoOperationTimeoutError(\n          `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n        ),\n        callback\n      );\n    }\n\n    stream.files\n      .insertOne(gridFSFile, { writeConcern: stream.writeConcern, timeoutMS: remainingTimeMS })\n      .then(\n        () => {\n          stream.gridFSFile = gridFSFile;\n          callback();\n        },\n        error => {\n          return handleError(stream, error, callback);\n        }\n      );\n    return;\n  }\n\n  process.nextTick(callback);\n}\n\nasync function checkIndexes(stream: GridFSBucketWriteStream): Promise<void> {\n  let remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n    `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n  );\n  const doc = await stream.files.findOne(\n    {},\n    {\n      projection: { _id: 1 },\n      timeoutMS: remainingTimeMS\n    }\n  );\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n\n  const index = { filename: 1, uploadDate: 1 };\n\n  let indexes;\n  remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n    `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n  );\n  const listIndexesOptions = {\n    timeoutMode: remainingTimeMS != null ? CursorTimeoutMode.LIFETIME : undefined,\n    timeoutMS: remainingTimeMS\n  };\n  try {\n    indexes = await stream.files.listIndexes(listIndexesOptions).toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasFileIndex) {\n    remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n    );\n\n    await stream.files.createIndex(index, { background: false, timeoutMS: remainingTimeMS });\n  }\n\n  await checkChunksIndex(stream);\n}\n\nfunction createFilesDoc(\n  _id: ObjectId,\n  length: number,\n  chunkSize: number,\n  filename: string,\n  contentType?: string,\n  aliases?: string[],\n  metadata?: Document\n): GridFSFile {\n  const ret: GridFSFile = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(\n  stream: GridFSBucketWriteStream,\n  chunk: Buffer | string,\n  encoding: BufferEncoding,\n  callback: Callback<void>\n): void {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n\n  stream.length += inputBuf.length;\n\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining: number = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc: GridFSChunk;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n\n      const remainingTimeMS = stream.timeoutContext?.remainingTimeMS;\n      if (remainingTimeMS != null && remainingTimeMS <= 0) {\n        return handleError(\n          stream,\n          new MongoOperationTimeoutError(\n            `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n          ),\n          callback\n        );\n      }\n\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (isAborted(stream, callback)) {\n        return;\n      }\n\n      stream.chunks\n        .insertOne(doc, { writeConcern: stream.writeConcern, timeoutMS: remainingTimeMS })\n        .then(\n          () => {\n            --stream.state.outstandingRequests;\n            --outstandingRequests;\n\n            if (!outstandingRequests) {\n              checkDone(stream, callback);\n            }\n          },\n          error => {\n            return handleError(stream, error, callback);\n          }\n        );\n\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\n\nfunction writeRemnant(stream: GridFSBucketWriteStream, callback: Callback): void {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n\n  const remainingTimeMS = stream.timeoutContext?.remainingTimeMS;\n  if (remainingTimeMS != null && remainingTimeMS <= 0) {\n    return handleError(\n      stream,\n      new MongoOperationTimeoutError(\n        `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n      ),\n      callback\n    );\n  }\n  ++stream.state.outstandingRequests;\n  stream.chunks\n    .insertOne(doc, { writeConcern: stream.writeConcern, timeoutMS: remainingTimeMS })\n    .then(\n      () => {\n        --stream.state.outstandingRequests;\n        checkDone(stream, callback);\n      },\n      error => {\n        return handleError(stream, error, callback);\n      }\n    );\n}\n\nfunction isAborted(stream: GridFSBucketWriteStream, callback: Callback<void>): boolean {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}\n"],"mappings":";;;;;;;AAAA,MAAAA,QAAA,GAAAC,OAAA;AAEA,MAAAC,MAAA,GAAAD,OAAA;AAEA,MAAAE,iBAAA,GAAAF,OAAA;AACA,MAAAG,OAAA,GAAAH,OAAA;AAMA,MAAAI,SAAA,GAAAJ,OAAA;AACA,MAAAK,OAAA,GAAAL,OAAA;AAEA,MAAAM,eAAA,GAAAN,OAAA;AAqCA;;;;;;AAMA,MAAaO,uBAAwB,SAAQR,QAAA,CAAAS,QAAQ;EAuDnD;;;;;;EAMAC,YAAYC,MAAoB,EAAEC,QAAgB,EAAEC,OAAwC;IAC1F,KAAK,EAAE;IAzBT;;;;;;;;;;;;;;IAcA,KAAAC,UAAU,GAAsB,IAAI;IAalCD,OAAO,GAAGA,OAAO,aAAPA,OAAO,cAAPA,OAAO,GAAI,EAAE;IACvB,IAAI,CAACF,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACI,MAAM,GAAGJ,MAAM,CAACK,CAAC,CAACC,iBAAiB;IACxC,IAAI,CAACL,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACM,KAAK,GAAGP,MAAM,CAACK,CAAC,CAACG,gBAAgB;IACtC,IAAI,CAACN,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACO,YAAY,GAAGb,eAAA,CAAAc,YAAY,CAACC,WAAW,CAACT,OAAO,CAAC,IAAIF,MAAM,CAACK,CAAC,CAACH,OAAO,CAACO,YAAY;IACtF;IACA,IAAI,CAACG,IAAI,GAAG,KAAK;IAEjB,IAAI,CAACC,EAAE,GAAGX,OAAO,CAACW,EAAE,GAAGX,OAAO,CAACW,EAAE,GAAG,IAAItB,MAAA,CAAAuB,QAAQ,EAAE;IAClD;IACA,IAAI,CAACC,cAAc,GAAGb,OAAO,CAACa,cAAc,IAAI,IAAI,CAACf,MAAM,CAACK,CAAC,CAACH,OAAO,CAACa,cAAc;IACpF,IAAI,CAACC,UAAU,GAAGC,MAAM,CAACC,KAAK,CAAC,IAAI,CAACH,cAAc,CAAC;IACnD,IAAI,CAACI,MAAM,GAAG,CAAC;IACf,IAAI,CAACC,CAAC,GAAG,CAAC;IACV,IAAI,CAACC,GAAG,GAAG,CAAC;IACZ,IAAI,CAACC,KAAK,GAAG;MACXC,SAAS,EAAE,KAAK;MAChBC,mBAAmB,EAAE,CAAC;MACtBC,OAAO,EAAE,KAAK;MACdC,OAAO,EAAE;KACV;IAED,IAAIxB,OAAO,CAACyB,SAAS,IAAI,IAAI,EAC3B,IAAI,CAACC,cAAc,GAAG,IAAIlC,SAAA,CAAAmC,kBAAkB,CAAC;MAC3CF,SAAS,EAAEzB,OAAO,CAACyB,SAAS;MAC5BG,wBAAwB,EAAE,IAAAnC,OAAA,CAAAoC,qBAAqB,EAAC,IAAI,CAAC/B,MAAM,CAACK,CAAC,CAAC2B,EAAE,CAACC,MAAM,EAAE,EAAE,CAAC,CACzEH;KACJ,CAAC;EACN;EAEA;;;;;EAKSI,UAAUA,CAACC,QAAwC;IAC1D,IAAI,CAAC,IAAI,CAACnC,MAAM,CAACK,CAAC,CAAC+B,sBAAsB,EAAE;MACzC,IAAI,CAACpC,MAAM,CAACK,CAAC,CAAC+B,sBAAsB,GAAG,IAAI;MAE3CC,YAAY,CAAC,IAAI,CAAC,CAACC,IAAI,CACrB,MAAK;QACH,IAAI,CAACtC,MAAM,CAACK,CAAC,CAACkC,cAAc,GAAG,IAAI;QACnC,IAAI,CAACvC,MAAM,CAACwC,IAAI,CAAC,OAAO,CAAC;QACzBL,QAAQ,EAAE;MACZ,CAAC,EACDM,KAAK,IAAG;QACN,IAAIA,KAAK,YAAYhD,OAAA,CAAAiD,0BAA0B,EAAE;UAC/C,OAAOC,WAAW,CAAC,IAAI,EAAEF,KAAK,EAAEN,QAAQ,CAAC;QAC3C;QACA,IAAAxC,OAAA,CAAAiD,WAAW,EAACH,KAAK,CAAC;QAClBN,QAAQ,EAAE;MACZ,CAAC,CACF;IACH,CAAC,MAAM;MACL,OAAOU,OAAO,CAACC,QAAQ,CAACX,QAAQ,CAAC;IACnC;EACF;EAEA;;;;;;;;EAQSY,MAAMA,CACbC,KAAsB,EACtBC,QAAwB,EACxBd,QAAwB;IAExBe,OAAO,CAAC,IAAI,EAAEF,KAAK,EAAEC,QAAQ,EAAEd,QAAQ,CAAC;EAC1C;EAEA;EACSgB,MAAMA,CAAChB,QAAwC;IACtD,IAAI,IAAI,CAACb,KAAK,CAACC,SAAS,EAAE;MACxB,OAAOsB,OAAO,CAACC,QAAQ,CAACX,QAAQ,CAAC;IACnC;IACA,IAAI,CAACb,KAAK,CAACC,SAAS,GAAG,IAAI;IAC3B6B,YAAY,CAAC,IAAI,EAAEjB,QAAQ,CAAC;EAC9B;EAEA;;;;EAIA,MAAMkB,KAAKA,CAAA;IAAA,IAAAC,oBAAA,EAAAC,qBAAA;IACT,IAAI,IAAI,CAACjC,KAAK,CAACC,SAAS,EAAE;MACxB;MACA,MAAM,IAAI9B,OAAA,CAAA+D,aAAa,CAAC,kDAAkD,CAAC;IAC7E;IAEA,IAAI,IAAI,CAAClC,KAAK,CAACI,OAAO,EAAE;MACtB;MACA,MAAM,IAAIjC,OAAA,CAAA+D,aAAa,CAAC,uCAAuC,CAAC;IAClE;IAEA,IAAI,CAAClC,KAAK,CAACI,OAAO,GAAG,IAAI;IACzB,MAAM+B,eAAe,IAAAH,oBAAA,GAAG,IAAI,CAAC1B,cAAc,cAAA0B,oBAAA,uBAAnBA,oBAAA,CAAqBI,yBAAyB,2BAAAC,MAAA,EAAAJ,qBAAA,GAC1C,IAAI,CAAC3B,cAAc,cAAA2B,qBAAA,uBAAnBA,qBAAA,CAAqB5B,SAAS,OAAI,CAC7D;IAED,MAAM,IAAI,CAACvB,MAAM,CAACwD,UAAU,CAAC;MAAEC,QAAQ,EAAE,IAAI,CAAChD;IAAE,CAAE,EAAE;MAAEc,SAAS,EAAE8B;IAAe,CAAE,CAAC;EACrF;;AA1KFK,OAAA,CAAAjE,uBAAA,GAAAA,uBAAA;AA6KA,SAAS8C,WAAWA,CAACoB,MAA+B,EAAEtB,KAAY,EAAEN,QAAkB;EACpF,IAAI4B,MAAM,CAACzC,KAAK,CAACG,OAAO,EAAE;IACxBoB,OAAO,CAACC,QAAQ,CAACX,QAAQ,CAAC;IAC1B;EACF;EACA4B,MAAM,CAACzC,KAAK,CAACG,OAAO,GAAG,IAAI;EAC3BoB,OAAO,CAACC,QAAQ,CAACX,QAAQ,EAAEM,KAAK,CAAC;AACnC;AAEA,SAASuB,cAAcA,CAACC,OAAiB,EAAE7C,CAAS,EAAE8C,IAAY;EAChE,OAAO;IACLC,GAAG,EAAE,IAAI5E,MAAA,CAAAuB,QAAQ,EAAE;IACnB+C,QAAQ,EAAEI,OAAO;IACjB7C,CAAC;IACD8C;GACD;AACH;AAEA,eAAeE,gBAAgBA,CAACL,MAA+B;EAAA,IAAAM,qBAAA,EAAAC,sBAAA;EAC7D,MAAMC,KAAK,GAAG;IAAEV,QAAQ,EAAE,CAAC;IAAEzC,CAAC,EAAE;EAAC,CAAE;EAEnC,IAAIqC,eAAe;EACnBA,eAAe,IAAAY,qBAAA,GAAGN,MAAM,CAACnC,cAAc,cAAAyC,qBAAA,uBAArBA,qBAAA,CAAuBX,yBAAyB,2BAAAC,MAAA,EAAAW,sBAAA,GACtCP,MAAM,CAACnC,cAAc,cAAA0C,sBAAA,uBAArBA,sBAAA,CAAuB3C,SAAS,OAAI,CAC/D;EAED,IAAI6C,OAAO;EACX,IAAI;IACFA,OAAO,GAAG,MAAMT,MAAM,CAAC3D,MAAM,CAC1BqE,WAAW,CAAC;MACXC,WAAW,EAAEjB,eAAe,IAAI,IAAI,GAAGjE,iBAAA,CAAAmF,iBAAiB,CAACC,QAAQ,GAAGC,SAAS;MAC7ElD,SAAS,EAAE8B;KACZ,CAAC,CACDqB,OAAO,EAAE;EACd,CAAC,CAAC,OAAOrC,KAAK,EAAE;IACd,IAAIA,KAAK,YAAYhD,OAAA,CAAAsF,UAAU,IAAItC,KAAK,CAACuC,IAAI,KAAKvF,OAAA,CAAAwF,mBAAmB,CAACC,iBAAiB,EAAE;MACvFV,OAAO,GAAG,EAAE;IACd,CAAC,MAAM;MACL,MAAM/B,KAAK;IACb;EACF;EAEA,MAAM0C,cAAc,GAAG,CAAC,CAACX,OAAO,CAACY,IAAI,CAACb,KAAK,IAAG;IAC5C,MAAMc,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACd,KAAK,CAACgB,GAAG,CAAC;IACnC,IAAIF,IAAI,CAAClE,MAAM,KAAK,CAAC,IAAIoD,KAAK,CAACgB,GAAG,CAAC1B,QAAQ,KAAK,CAAC,IAAIU,KAAK,CAACgB,GAAG,CAACnE,CAAC,KAAK,CAAC,EAAE;MACtE,OAAO,IAAI;IACb;IACA,OAAO,KAAK;EACd,CAAC,CAAC;EAEF,IAAI,CAAC+D,cAAc,EAAE;IAAA,IAAAK,sBAAA,EAAAC,sBAAA;IACnBhC,eAAe,IAAA+B,sBAAA,GAAGzB,MAAM,CAACnC,cAAc,cAAA4D,sBAAA,uBAArBA,sBAAA,CAAuB9B,yBAAyB,2BAAAC,MAAA,EAAA8B,sBAAA,GACtC1B,MAAM,CAACnC,cAAc,cAAA6D,sBAAA,uBAArBA,sBAAA,CAAuB9D,SAAS,OAAI,CAC/D;IACD,MAAMoC,MAAM,CAAC3D,MAAM,CAACsF,WAAW,CAACnB,KAAK,EAAAoB,aAAA,CAAAA,aAAA,KAChC5B,MAAM,CAACtD,YAAY;MACtBmF,UAAU,EAAE,IAAI;MAChBC,MAAM,EAAE,IAAI;MACZlE,SAAS,EAAE8B;IAAe,EAC3B,CAAC;EACJ;AACF;AAEA,SAASqC,SAASA,CAAC/B,MAA+B,EAAE5B,QAAkB;EACpE,IAAI4B,MAAM,CAACnD,IAAI,EAAE;IACf,OAAOiC,OAAO,CAACC,QAAQ,CAACX,QAAQ,CAAC;EACnC;EAEA,IAAI4B,MAAM,CAACzC,KAAK,CAACC,SAAS,IAAIwC,MAAM,CAACzC,KAAK,CAACE,mBAAmB,KAAK,CAAC,IAAI,CAACuC,MAAM,CAACzC,KAAK,CAACG,OAAO,EAAE;IAAA,IAAAsE,sBAAA;IAC7F;IACAhC,MAAM,CAACnD,IAAI,GAAG,IAAI;IAClB;IACA,MAAMT,UAAU,GAAG6F,cAAc,CAC/BjC,MAAM,CAAClD,EAAE,EACTkD,MAAM,CAAC5C,MAAM,EACb4C,MAAM,CAAChD,cAAc,EACrBgD,MAAM,CAAC9D,QAAQ,EACf8D,MAAM,CAAC7D,OAAO,CAAC+F,WAAW,EAC1BlC,MAAM,CAAC7D,OAAO,CAACgG,OAAO,EACtBnC,MAAM,CAAC7D,OAAO,CAACiG,QAAQ,CACxB;IAED,IAAIC,SAAS,CAACrC,MAAM,EAAE5B,QAAQ,CAAC,EAAE;MAC/B;IACF;IAEA,MAAMsB,eAAe,IAAAsC,sBAAA,GAAGhC,MAAM,CAACnC,cAAc,cAAAmE,sBAAA,uBAArBA,sBAAA,CAAuBtC,eAAe;IAC9D,IAAIA,eAAe,IAAI,IAAI,IAAIA,eAAe,IAAI,CAAC,EAAE;MAAA,IAAA4C,sBAAA;MACnD,OAAO1D,WAAW,CAChBoB,MAAM,EACN,IAAItE,OAAA,CAAAiD,0BAA0B,2BAAAiB,MAAA,EAAA0C,sBAAA,GACFtC,MAAM,CAACnC,cAAc,cAAAyE,sBAAA,uBAArBA,sBAAA,CAAuB1E,SAAS,OAAI,CAC/D,EACDQ,QAAQ,CACT;IACH;IAEA4B,MAAM,CAACxD,KAAK,CACT+F,SAAS,CAACnG,UAAU,EAAE;MAAEM,YAAY,EAAEsD,MAAM,CAACtD,YAAY;MAAEkB,SAAS,EAAE8B;IAAe,CAAE,CAAC,CACxFnB,IAAI,CACH,MAAK;MACHyB,MAAM,CAAC5D,UAAU,GAAGA,UAAU;MAC9BgC,QAAQ,EAAE;IACZ,CAAC,EACDM,KAAK,IAAG;MACN,OAAOE,WAAW,CAACoB,MAAM,EAAEtB,KAAK,EAAEN,QAAQ,CAAC;IAC7C,CAAC,CACF;IACH;EACF;EAEAU,OAAO,CAACC,QAAQ,CAACX,QAAQ,CAAC;AAC5B;AAEA,eAAeE,YAAYA,CAAC0B,MAA+B;EAAA,IAAAwC,sBAAA,EAAAC,sBAAA,EAAAC,sBAAA,EAAAC,uBAAA;EACzD,IAAIjD,eAAe,IAAA8C,sBAAA,GAAGxC,MAAM,CAACnC,cAAc,cAAA2E,sBAAA,uBAArBA,sBAAA,CAAuB7C,yBAAyB,2BAAAC,MAAA,EAAA6C,sBAAA,GAC1CzC,MAAM,CAACnC,cAAc,cAAA4E,sBAAA,uBAArBA,sBAAA,CAAuB7E,SAAS,OAAI,CAC/D;EACD,MAAMgF,GAAG,GAAG,MAAM5C,MAAM,CAACxD,KAAK,CAACqG,OAAO,CACpC,EAAE,EACF;IACEC,UAAU,EAAE;MAAE1C,GAAG,EAAE;IAAC,CAAE;IACtBxC,SAAS,EAAE8B;GACZ,CACF;EACD,IAAIkD,GAAG,IAAI,IAAI,EAAE;IACf;IACA;EACF;EAEA,MAAMpC,KAAK,GAAG;IAAEtE,QAAQ,EAAE,CAAC;IAAE6G,UAAU,EAAE;EAAC,CAAE;EAE5C,IAAItC,OAAO;EACXf,eAAe,IAAAgD,sBAAA,GAAG1C,MAAM,CAACnC,cAAc,cAAA6E,sBAAA,uBAArBA,sBAAA,CAAuB/C,yBAAyB,2BAAAC,MAAA,EAAA+C,uBAAA,GACtC3C,MAAM,CAACnC,cAAc,cAAA8E,uBAAA,uBAArBA,uBAAA,CAAuB/E,SAAS,OAAI,CAC/D;EACD,MAAMoF,kBAAkB,GAAG;IACzBrC,WAAW,EAAEjB,eAAe,IAAI,IAAI,GAAGjE,iBAAA,CAAAmF,iBAAiB,CAACC,QAAQ,GAAGC,SAAS;IAC7ElD,SAAS,EAAE8B;GACZ;EACD,IAAI;IACFe,OAAO,GAAG,MAAMT,MAAM,CAACxD,KAAK,CAACkE,WAAW,CAACsC,kBAAkB,CAAC,CAACjC,OAAO,EAAE;EACxE,CAAC,CAAC,OAAOrC,KAAK,EAAE;IACd,IAAIA,KAAK,YAAYhD,OAAA,CAAAsF,UAAU,IAAItC,KAAK,CAACuC,IAAI,KAAKvF,OAAA,CAAAwF,mBAAmB,CAACC,iBAAiB,EAAE;MACvFV,OAAO,GAAG,EAAE;IACd,CAAC,MAAM;MACL,MAAM/B,KAAK;IACb;EACF;EAEA,MAAMuE,YAAY,GAAG,CAAC,CAACxC,OAAO,CAACY,IAAI,CAACb,KAAK,IAAG;IAC1C,MAAMc,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACd,KAAK,CAACgB,GAAG,CAAC;IACnC,IAAIF,IAAI,CAAClE,MAAM,KAAK,CAAC,IAAIoD,KAAK,CAACgB,GAAG,CAACtF,QAAQ,KAAK,CAAC,IAAIsE,KAAK,CAACgB,GAAG,CAACuB,UAAU,KAAK,CAAC,EAAE;MAC/E,OAAO,IAAI;IACb;IACA,OAAO,KAAK;EACd,CAAC,CAAC;EAEF,IAAI,CAACE,YAAY,EAAE;IAAA,IAAAC,uBAAA,EAAAC,uBAAA;IACjBzD,eAAe,IAAAwD,uBAAA,GAAGlD,MAAM,CAACnC,cAAc,cAAAqF,uBAAA,uBAArBA,uBAAA,CAAuBvD,yBAAyB,2BAAAC,MAAA,EAAAuD,uBAAA,GACtCnD,MAAM,CAACnC,cAAc,cAAAsF,uBAAA,uBAArBA,uBAAA,CAAuBvF,SAAS,OAAI,CAC/D;IAED,MAAMoC,MAAM,CAACxD,KAAK,CAACmF,WAAW,CAACnB,KAAK,EAAE;MAAEqB,UAAU,EAAE,KAAK;MAAEjE,SAAS,EAAE8B;IAAe,CAAE,CAAC;EAC1F;EAEA,MAAMW,gBAAgB,CAACL,MAAM,CAAC;AAChC;AAEA,SAASiC,cAAcA,CACrB7B,GAAa,EACbhD,MAAc,EACdgG,SAAiB,EACjBlH,QAAgB,EAChBgG,WAAoB,EACpBC,OAAkB,EAClBC,QAAmB;EAEnB,MAAMiB,GAAG,GAAe;IACtBjD,GAAG;IACHhD,MAAM;IACNgG,SAAS;IACTL,UAAU,EAAE,IAAIO,IAAI,EAAE;IACtBpH;GACD;EAED,IAAIgG,WAAW,EAAE;IACfmB,GAAG,CAACnB,WAAW,GAAGA,WAAW;EAC/B;EAEA,IAAIC,OAAO,EAAE;IACXkB,GAAG,CAAClB,OAAO,GAAGA,OAAO;EACvB;EAEA,IAAIC,QAAQ,EAAE;IACZiB,GAAG,CAACjB,QAAQ,GAAGA,QAAQ;EACzB;EAEA,OAAOiB,GAAG;AACZ;AAEA,SAASlE,OAAOA,CACda,MAA+B,EAC/Bf,KAAsB,EACtBC,QAAwB,EACxBd,QAAwB;EAExB,IAAIiE,SAAS,CAACrC,MAAM,EAAE5B,QAAQ,CAAC,EAAE;IAC/B;EACF;EAEA,MAAMmF,QAAQ,GAAGrG,MAAM,CAACsG,QAAQ,CAACvE,KAAK,CAAC,GAAGA,KAAK,GAAG/B,MAAM,CAACuG,IAAI,CAACxE,KAAK,EAAEC,QAAQ,CAAC;EAE9Ec,MAAM,CAAC5C,MAAM,IAAImG,QAAQ,CAACnG,MAAM;EAEhC;EACA,IAAI4C,MAAM,CAAC1C,GAAG,GAAGiG,QAAQ,CAACnG,MAAM,GAAG4C,MAAM,CAAChD,cAAc,EAAE;IACxDuG,QAAQ,CAACG,IAAI,CAAC1D,MAAM,CAAC/C,UAAU,EAAE+C,MAAM,CAAC1C,GAAG,CAAC;IAC5C0C,MAAM,CAAC1C,GAAG,IAAIiG,QAAQ,CAACnG,MAAM;IAC7B0B,OAAO,CAACC,QAAQ,CAACX,QAAQ,CAAC;IAC1B;EACF;EAEA;EACA;EACA,IAAIuF,iBAAiB,GAAGJ,QAAQ,CAACnG,MAAM;EACvC,IAAIwG,cAAc,GAAW5D,MAAM,CAAChD,cAAc,GAAGgD,MAAM,CAAC1C,GAAG;EAC/D,IAAIuG,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAEL,QAAQ,CAACnG,MAAM,CAAC;EACzD,IAAIK,mBAAmB,GAAG,CAAC;EAC3B,OAAOkG,iBAAiB,GAAG,CAAC,EAAE;IAC5B,MAAMK,WAAW,GAAGT,QAAQ,CAACnG,MAAM,GAAGuG,iBAAiB;IACvDJ,QAAQ,CAACG,IAAI,CAAC1D,MAAM,CAAC/C,UAAU,EAAE+C,MAAM,CAAC1C,GAAG,EAAE0G,WAAW,EAAEA,WAAW,GAAGH,SAAS,CAAC;IAClF7D,MAAM,CAAC1C,GAAG,IAAIuG,SAAS;IACvBD,cAAc,IAAIC,SAAS;IAC3B,IAAIjB,GAAgB;IACpB,IAAIgB,cAAc,KAAK,CAAC,EAAE;MAAA,IAAAK,uBAAA;MACxBrB,GAAG,GAAG3C,cAAc,CAACD,MAAM,CAAClD,EAAE,EAAEkD,MAAM,CAAC3C,CAAC,EAAEH,MAAM,CAACuG,IAAI,CAACzD,MAAM,CAAC/C,UAAU,CAAC,CAAC;MAEzE,MAAMyC,eAAe,IAAAuE,uBAAA,GAAGjE,MAAM,CAACnC,cAAc,cAAAoG,uBAAA,uBAArBA,uBAAA,CAAuBvE,eAAe;MAC9D,IAAIA,eAAe,IAAI,IAAI,IAAIA,eAAe,IAAI,CAAC,EAAE;QAAA,IAAAwE,uBAAA;QACnD,OAAOtF,WAAW,CAChBoB,MAAM,EACN,IAAItE,OAAA,CAAAiD,0BAA0B,2BAAAiB,MAAA,EAAAsE,uBAAA,GACFlE,MAAM,CAACnC,cAAc,cAAAqG,uBAAA,uBAArBA,uBAAA,CAAuBtG,SAAS,OAAI,CAC/D,EACDQ,QAAQ,CACT;MACH;MAEA,EAAE4B,MAAM,CAACzC,KAAK,CAACE,mBAAmB;MAClC,EAAEA,mBAAmB;MAErB,IAAI4E,SAAS,CAACrC,MAAM,EAAE5B,QAAQ,CAAC,EAAE;QAC/B;MACF;MAEA4B,MAAM,CAAC3D,MAAM,CACVkG,SAAS,CAACK,GAAG,EAAE;QAAElG,YAAY,EAAEsD,MAAM,CAACtD,YAAY;QAAEkB,SAAS,EAAE8B;MAAe,CAAE,CAAC,CACjFnB,IAAI,CACH,MAAK;QACH,EAAEyB,MAAM,CAACzC,KAAK,CAACE,mBAAmB;QAClC,EAAEA,mBAAmB;QAErB,IAAI,CAACA,mBAAmB,EAAE;UACxBsE,SAAS,CAAC/B,MAAM,EAAE5B,QAAQ,CAAC;QAC7B;MACF,CAAC,EACDM,KAAK,IAAG;QACN,OAAOE,WAAW,CAACoB,MAAM,EAAEtB,KAAK,EAAEN,QAAQ,CAAC;MAC7C,CAAC,CACF;MAEHwF,cAAc,GAAG5D,MAAM,CAAChD,cAAc;MACtCgD,MAAM,CAAC1C,GAAG,GAAG,CAAC;MACd,EAAE0C,MAAM,CAAC3C,CAAC;IACZ;IACAsG,iBAAiB,IAAIE,SAAS;IAC9BA,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAED,iBAAiB,CAAC;EACzD;AACF;AAEA,SAAStE,YAAYA,CAACW,MAA+B,EAAE5B,QAAkB;EAAA,IAAA+F,uBAAA;EACvE;EACA,IAAInE,MAAM,CAAC1C,GAAG,KAAK,CAAC,EAAE;IACpB,OAAOyE,SAAS,CAAC/B,MAAM,EAAE5B,QAAQ,CAAC;EACpC;EAEA;EACA;EACA,MAAMgG,OAAO,GAAGlH,MAAM,CAACC,KAAK,CAAC6C,MAAM,CAAC1C,GAAG,CAAC;EACxC0C,MAAM,CAAC/C,UAAU,CAACyG,IAAI,CAACU,OAAO,EAAE,CAAC,EAAE,CAAC,EAAEpE,MAAM,CAAC1C,GAAG,CAAC;EACjD,MAAMsF,GAAG,GAAG3C,cAAc,CAACD,MAAM,CAAClD,EAAE,EAAEkD,MAAM,CAAC3C,CAAC,EAAE+G,OAAO,CAAC;EAExD;EACA,IAAI/B,SAAS,CAACrC,MAAM,EAAE5B,QAAQ,CAAC,EAAE;IAC/B;EACF;EAEA,MAAMsB,eAAe,IAAAyE,uBAAA,GAAGnE,MAAM,CAACnC,cAAc,cAAAsG,uBAAA,uBAArBA,uBAAA,CAAuBzE,eAAe;EAC9D,IAAIA,eAAe,IAAI,IAAI,IAAIA,eAAe,IAAI,CAAC,EAAE;IAAA,IAAA2E,uBAAA;IACnD,OAAOzF,WAAW,CAChBoB,MAAM,EACN,IAAItE,OAAA,CAAAiD,0BAA0B,2BAAAiB,MAAA,EAAAyE,uBAAA,GACFrE,MAAM,CAACnC,cAAc,cAAAwG,uBAAA,uBAArBA,uBAAA,CAAuBzG,SAAS,OAAI,CAC/D,EACDQ,QAAQ,CACT;EACH;EACA,EAAE4B,MAAM,CAACzC,KAAK,CAACE,mBAAmB;EAClCuC,MAAM,CAAC3D,MAAM,CACVkG,SAAS,CAACK,GAAG,EAAE;IAAElG,YAAY,EAAEsD,MAAM,CAACtD,YAAY;IAAEkB,SAAS,EAAE8B;EAAe,CAAE,CAAC,CACjFnB,IAAI,CACH,MAAK;IACH,EAAEyB,MAAM,CAACzC,KAAK,CAACE,mBAAmB;IAClCsE,SAAS,CAAC/B,MAAM,EAAE5B,QAAQ,CAAC;EAC7B,CAAC,EACDM,KAAK,IAAG;IACN,OAAOE,WAAW,CAACoB,MAAM,EAAEtB,KAAK,EAAEN,QAAQ,CAAC;EAC7C,CAAC,CACF;AACL;AAEA,SAASiE,SAASA,CAACrC,MAA+B,EAAE5B,QAAwB;EAC1E,IAAI4B,MAAM,CAACzC,KAAK,CAACI,OAAO,EAAE;IACxBmB,OAAO,CAACC,QAAQ,CAACX,QAAQ,EAAE,IAAI1C,OAAA,CAAA+D,aAAa,CAAC,yBAAyB,CAAC,CAAC;IACxE,OAAO,IAAI;EACb;EACA,OAAO,KAAK;AACd","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}